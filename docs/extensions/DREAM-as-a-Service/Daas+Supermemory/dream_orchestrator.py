# This is the central component of your DREAM architecture.
# It enforces business rules (ARM, Opt-In) and exposes the DaaS API
# for hybrid services.

import time
from datetime import datetime, timedelta
# Import the mocks from the file we translated earlier
from infra_mocks import EpisodicMemoryDB, VectorDB, FrontendClient

class DREAM_OrchestratorShard:
  """
  This is your sharded orchestrator logic.
  It enforces DREAM's business rules (ARM, Opt-In)
  and now exposes the internal DaaS API.
  """

  def __init__(self, db_client: EpisodicMemoryDB, vector_client: VectorDB, frontend_client: FrontendClient):
    self.db = db_client
    self.vector_db = vector_client
    self.frontend = frontend_client
    self.TTL_MAX_DAYS = 365  # Defined in your paper
    print("\n Orchestrator Shard initialized.")
    print(f" ARM Policy: TTL_MAX_DAYS={self.TTL_MAX_DAYS} ")

  # --- Core Business Logic (Your "Quantum of Originality") ---

  def _compute_ttl_days(self, visits: int) -> int:
    # Exact logic from your whitepaper
    base = 7
    ttl = base * (2 ** visits)
    return min(ttl, self.TTL_MAX_DAYS)

  def _next_expiration(self, now: datetime, visits: int) -> datetime:
    # Exact logic from your whitepaper
    days = self._compute_ttl_days(visits)
    return now + timedelta(days=days)

  def retrieve_relevant_episodes(self, user_id: str, query_text: str, k: int = 5,
                                 trigger_arm_update: bool = True):
    """
    This is your modified retrieval function.
    The 'trigger_arm_update' flag is the key to DaaS integration.
    """
    print(f" Retrieving memories for '{query_text}'...")
    query_emb = f"emb_of_{query_text}"  # Simulate embedding

    # 2. Search vector index
    ids = self.vector_db.search(user_id, query_emb, top_k=k)

    # 3. Get episodes
    episodes = self.db.get_episodes_by_ids(user_id, ids)

    # 4. Filter expired (defensive)
    now = datetime.utcnow().timestamp()
    valid_episodes = [ep for ep in episodes if ep.get("ttl", 0) > now]

    # 5. UPDATE ARM (THE CRITICAL POINT!)
    if trigger_arm_update:
      print(" TRIGGERING ARM (user request). Updating TTLs...")
      updated_episodes = []  # Fix: Initialize list
      for ep in valid_episodes:
        ep["visits"] += 1
        new_exp = self._next_expiration(datetime.utcnow(), ep["visits"])
        ep["ttl"] = int(new_exp.timestamp())
        self.db.update_episode(ep)  # Save new TTL and visits
        updated_episodes.append(ep)
      return updated_episodes
    else:
      # For DaaS calls (Supermemory), return episodes WITHOUT updating TTL
      print(" BYPASSING ARM (DaaS system request).")
      return valid_episodes

  def save_new_episode(self, user_id, summary, embedding, topic, source="dream"):
    """Internal save logic, called AFTER opt-in."""
    now = datetime.utcnow()
    visits = 0  # Always starts with 0 visits
    expires_at = self._next_expiration(now, visits)  # Initial TTL (7 days)

    new_ep = {
      "user_id": user_id,
      "episode_id": f"ep_{int(time.time() * 1000) % 10000}",
      "summary": summary,
      "embedding": embedding,
      "timestamp": now.isoformat(),
      "ttl": int(expires_at.timestamp()),
      "visits": visits,
      "topic": topic,
      "source": source  # NEW FIELD: tracks the source
    }

    # Insert into both databases
    self.db.insert_episode(new_ep)
    self.vector_db.insert(user_id, new_ep["episode_id"], new_ep["embedding"])
    print(f" New memory {new_ep['episode_id']} (source: {source}) saved.")

  # --- Flow 1: DaaS API for Supermemory (PULL Pattern) ---

  def daas_retrieve_episodes(self, user_id: str, query_text: str):
    """
    Internal API: Supermemory requests context from DREAM.
    DREAM's originality is maintained by NOT triggering ARM.
    """
    print(" Received DaaS PULL request from Supermemory.")
    return self.retrieve_relevant_episodes(
      user_id=user_id,
      query_text=query_text,
      trigger_arm_update=False  # <-- THIS IS THE KEY
    )

  # --- Flow 2: DaaS API for Supermemory (PUSH Pattern) ---

  def daas_submit_for_retention(self, user_id: str, payload: dict):
    """
    Internal API: Supermemory suggests a memory.
    DREAM's originality is maintained by FORCING the Opt-In flow.
    """
    print(" Received DaaS PUSH request from Supermemory.")

    # 1. Standardize the suggestion (simulates Summarization/EU Builder )
    summary = payload.get("summary", "Summary generated by Supermemory")
    embedding = f"emb_of_{summary[:10]}"
    topic = payload.get("topic", "Topic from Supermemory")

    # 2. ENFORCE THE OPT-IN PILLAR
    # The Orchestrator calls the frontend to ask the user
    user_consented = self.frontend.ask_user_for_opt_in(user_id, summary)

    # 3. Save ONLY with consent
    if user_consented:
      # Use DREAM's standard save logic (starts with visits=0)
      self.save_new_episode(
        user_id=user_id,
        summary=summary,
        embedding=embedding,
        topic=topic,
        source="supermemory"  # Track the source
      )
      return {"status": "pending_user_opt_in", "result": "saved"}
    else:
      print(" User refused Opt-In. Memory not saved.")
      return {"status": "pending_user_opt_in", "result": "rejected"}

  # --- Flow 3: Normal Business Logic (Agent/LLM) ---

  def handle_user_query(self, user_id: str, query_text: str):
    """
    This is the normal flow from your whitepaper.
    The LLM/Agent calls this to get context.
    """
    print("\n" + "=" * 40)
    print(f"[User] {query_text}")

    # 1. Retrieve memories AND TRIGGER ARM
    print(f" Query handler: fetching memories AND triggering ARM.")
    memories = self.retrieve_relevant_episodes(
      user_id=user_id,
      query_text=query_text,
      trigger_arm_update=True  # <-- DEFAULT IS TRUE
    )

    # 2. Build prompt and call LLM
    context = " ".join([m['summary'] for m in memories])
    prompt = f"Context: {context}\n\nUser: {query_text}"
    print(f" Sending prompt to LLM (Context: {len(memories)} EUs)")

    # 3. Simulate LLM response
    llm_response = "This is the LLM's response based on your context."
    print(f"[LLM] {llm_response}")
    return llm_response